{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be255d60-884d-4ffe-ae4f-9bb82503b27c",
   "metadata": {},
   "source": [
    "# Generating Fractional Cover\n",
    "\n",
    "## Apply DEA fractional cover endmember/model coefficients to landsat surface reflectance - similar to what is done from DEAfrica [**here**](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks/blob/main/Datasets/Fractional_Cover.ipynb)\n",
    "\n",
    "- [DEA product and algorithm details](https://www.dea.ga.gov.au/products/dea-fractional-cover)\n",
    "\n",
    "This notebook requires the \"FC_Environment\", which needs to be installed as in the first cell of this notebook (to be run on commandline). Once done, set the environment in the top-right corner. \n",
    "\n",
    "\n",
    "**Notes 24/3/23**\n",
    "- landsat8_c2l2_sr scaling is not applied as fractional cover algo needs 0-10000 values of surface reflectance (SR)\n",
    "- cannot get dask cluster working, error messages occur with using `.compute()` suggesting datasets cannot be found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674c9ee-e1e3-4b5f-aee4-ab01b5d6f445",
   "metadata": {},
   "source": [
    "#### Install the WOfS environment using the following on command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f78146f-7193-48c7-828d-749f39d0c462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npython3 -m venv ~/venvs/FC_Environment\\nsource ~/venvs/FC_Environment/bin/activate\\ndeactivate\\nrealpath /env/lib/python3.10/site-packages > ~/venvs/FC_Environment/lib/python3.10/site-packages/base_venv.pth\\nsource ~/venvs/FC_Environment/bin/activate\\npip install --extra-index-url=https://packages.dea.ga.gov.au/ fc\\npython -m ipykernel install --user --name=FC_Environment\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "python3 -m venv ~/venvs/FC_Environment\n",
    "source ~/venvs/FC_Environment/bin/activate\n",
    "deactivate\n",
    "realpath /env/lib/python3.10/site-packages > ~/venvs/FC_Environment/lib/python3.10/site-packages/base_venv.pth\n",
    "source ~/venvs/FC_Environment/bin/activate\n",
    "pip install --extra-index-url=https://packages.dea.ga.gov.au/ fc\n",
    "python -m ipykernel install --user --name=FC_Environment\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872fcce9-4c19-4480-98df-a3b66679f2b6",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b250fe-4208-440d-9026-e51ca01e5f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from itertools import groupby\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import datacube\n",
    "from datacube.utils import masking  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/masking.py\n",
    "from datacube.utils.cog import write_cog\n",
    "\n",
    "from fc.fractional_cover import fractional_cover\n",
    "\n",
    "from dea_tools.plotting import rgb, display_map\n",
    "from dea_tools.dask import create_local_dask_cluster\n",
    "from datacube.drivers.netcdf import write_dataset_to_netcdf\n",
    "\n",
    "dc = datacube.Datacube(app='Generating_FractionalCover')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f877258-186a-4737-8d86-371f8b3127ac",
   "metadata": {},
   "source": [
    "#### AWS Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60baf244-a31e-4142-ac07-62b4e54935e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Optional: Access AWS \"requester-pays\" buckets\n",
    "# This is necessary for Landsat (\"landsatN_c2l2_*\") and Sentinel-2 (\"s2_l2a\") products\n",
    "from datacube.utils.aws import configure_s3_access\n",
    "configure_s3_access(aws_unsigned=False, requester_pays=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a91ca-cbd1-4d4a-bb48-cabff8eaba78",
   "metadata": {},
   "source": [
    "#### display AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac095e1-fa49-4b00-b8e7-18bc366b5e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_7d5e8c8e96a3b47a42c88dad1dbb3bad {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_7d5e8c8e96a3b47a42c88dad1dbb3bad&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_7d5e8c8e96a3b47a42c88dad1dbb3bad = L.map(\n",
       "                &quot;map_7d5e8c8e96a3b47a42c88dad1dbb3bad&quot;,\n",
       "                {\n",
       "                    center: [-7.35, 144.45],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 12,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_ccad4c7d53887c1fc0d0d35dbaf15fd7 = L.tileLayer(\n",
       "                &quot;http://mt1.google.com/vt/lyrs=y\\u0026z={z}\\u0026x={x}\\u0026y={y}&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Google&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_7d5e8c8e96a3b47a42c88dad1dbb3bad);\n",
       "        \n",
       "    \n",
       "            var poly_line_dac5e1f7405c1186cad536d690cbfe3e = L.polyline(\n",
       "                [[-7.3, 144.4], [-7.3, 144.5], [-7.4, 144.5], [-7.4, 144.4], [-7.3, 144.4]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;red&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;red&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 0.8, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_7d5e8c8e96a3b47a42c88dad1dbb3bad);\n",
       "        \n",
       "    \n",
       "                var lat_lng_popup_a7a8c1401a21943039d06b4eda9b919d = L.popup();\n",
       "                function latLngPop(e) {\n",
       "                    lat_lng_popup_a7a8c1401a21943039d06b4eda9b919d\n",
       "                        .setLatLng(e.latlng)\n",
       "                        .setContent(&quot;Latitude: &quot; + e.latlng.lat.toFixed(4) +\n",
       "                                    &quot;&lt;br&gt;Longitude: &quot; + e.latlng.lng.toFixed(4))\n",
       "                        .openOn(map_7d5e8c8e96a3b47a42c88dad1dbb3bad);\n",
       "                    }\n",
       "                map_7d5e8c8e96a3b47a42c88dad1dbb3bad.on(&#x27;click&#x27;, latLngPop);\n",
       "            \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f510201ee30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitude = (-7.3, -7.4)\n",
    "longitude = (144.4, 144.5)\n",
    "display_map(longitude, latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5557d-e1b4-4c99-81ca-31c546e5761a",
   "metadata": {},
   "source": [
    "#### Load landsat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5dc798e-c364-4bf6-a6b9-997d4b9450ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set time range\n",
    "time = ('2020-01-01', '2020-12-31')\n",
    "\n",
    "# Load the data\n",
    "ds = dc.load(\n",
    "    product='landsat8_c2l2_sr',\n",
    "    latitude=latitude,\n",
    "    longitude=longitude,\n",
    "    time=time,\n",
    "    measurements=['blue', 'green', 'red', 'nir08', 'swir16', 'swir22', 'qa_pixel'],\n",
    "    output_crs=\"EPSG:32755\",\n",
    "    resolution=(100, -100),\n",
    "    group_by='solar_day',\n",
    "    dask_chunks={'time': 1, 'x': 100, 'y': 100}\n",
    ")\n",
    "\n",
    "# Rename the data variables to match the fractional cover function's requirements\n",
    "ds = ds.rename({\n",
    "    \"nir08\": \"nir\",\n",
    "    \"swir16\": \"swir1\",\n",
    "    \"swir22\": \"swir2\",\n",
    "    \"qa_pixel\": \"fmask\",\n",
    "})\n",
    "\n",
    "ds = ds.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603462e-285f-44c0-bf91-cf71a5284b9f",
   "metadata": {},
   "source": [
    "#### mask cloudy data (no need to scale as is in the correct 0-10000 for fractional cover algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43a27cb-aaf4-4e99-8da9-205716d6f787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a mask array for the nodata value\n",
    "valid_mask = masking.valid_data_mask(ds)\n",
    "\n",
    "# Make a cloud mask (landsat8_c2l2_sr)\n",
    "# Multiple flags are combined as logical AND (bitwise)\n",
    "cloud_mask = masking.make_mask(ds['fmask'], clear='clear')\n",
    "\n",
    "# Apply each of the masks\n",
    "filtered_data = ds.where(valid_mask & cloud_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022ff2e-944e-4877-97b5-6ccc09320293",
   "metadata": {},
   "source": [
    "#### run `fractional_cover` algo for each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d82eecea-eef6-4345-9320-a07b3b06bcc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create ds_fc for each time step and concatenate them along time dimension\n",
    "ds_fc_list = []\n",
    "for t in filtered_data.time:\n",
    "    ds_t = filtered_data.sel(time=t)\n",
    "    ds_fc_t = fractional_cover(ds_t)\n",
    "    ds_fc_list.append(ds_fc_t)\n",
    "\n",
    "ds_fc = xr.concat(ds_fc_list, dim='time').transpose('time', 'y', 'x')\n",
    "# correct times added back in\n",
    "ds_fc['time'] = filtered_data.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660fd358-7949-4d1a-a00f-2cc6f51a138e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plotting up to see amount of good available\n",
    "ds_fc.PV.plot(col=\"time\", col_wrap=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ebef8-523b-415b-adbf-7c23d25c91c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export out as .nc to allow load back in easily as xarray\n",
    "write_dataset_to_netcdf(ds_fc, '../data/fractionalcover_test.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e826a7-667a-415d-9ed3-40381b1112be",
   "metadata": {},
   "source": [
    "### make annual percentiles (90th percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57a5ec-4ce9-4987-9bb8-1e485aba3952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace negative values with NaN\n",
    "ds_fc = ds_fc.where(ds_fc >= 0)  \n",
    "\n",
    "# Resample to annual frequency and skip NaN values\n",
    "ds_fc_annual = ds_fc.resample(time='A').mean(skipna=True)\n",
    "\n",
    "# Calculate percentiles\n",
    "fc_percentile_annual = ds_fc_annual.quantile(q=[0.9], dim='time')\n",
    "\n",
    "# Convert to percentages and rename variables\n",
    "# fc_percentile_annual = fc_percentile_annual * 100\n",
    "fc_percentile_annual = fc_percentile_annual.rename({'PV': 'PV_PC_90',\n",
    "                                         'NPV': 'NPV_PC_90',\n",
    "                                         'BS': 'BS_PC_90',\n",
    "                                         'UE': 'UE_PC_90'})\n",
    "# remove 'quantile' dim\n",
    "fc_percentile_annual = fc_percentile_annual.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13fe40-86eb-47c6-8363-0b71de995ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "\n",
    "fc_percentile_annual['PV_PC_90'].plot(ax=axs[0,0], vmin=0, vmax=100)\n",
    "axs[0,0].set_title('PV_PC_90')\n",
    "\n",
    "fc_percentile_annual['NPV_PC_90'].plot(ax=axs[0,1], vmin=0, vmax=100)\n",
    "axs[0,1].set_title('NPV_PC_90')\n",
    "\n",
    "fc_percentile_annual['BS_PC_90'].plot(ax=axs[1,0], vmin=0, vmax=100)\n",
    "axs[1,0].set_title('BS_PC_90')\n",
    "\n",
    "fc_percentile_annual['UE_PC_90'].plot(ax=axs[1,1], vmin=0, vmax=100)\n",
    "axs[1,1].set_title('UE_PC_90')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecd609-f8cd-42d6-87ef-b3a7fcc5ea55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export out as .nc to allow load back in easily as xarray\n",
    "write_dataset_to_netcdf(ds_fc, '../data/fractionalcover_annual90thpercentile_test.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7eef9a-1699-494b-9004-4e5e13876af0",
   "metadata": {},
   "source": [
    "### example using similar percentiles for veg/non veg at level 1 - similar to [**here**](https://bitbucket.org/au-eoed/livingearth_lccs_development_tests/src/master/notebooks/level3/le_lccs_dea_level3_tests.ipynb?viewer=nbviewer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37676e4-fe4f-4f0a-971c-812e384f40c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "level1 = ((fc_percentile_annual[\"PV_PC_90\"] >= 50) | ((fc_percentile_annual[\"NPV_PC_90\"] >= 50) & (fc_percentile_annual[\"NPV_PC_90\"] <= 80)))\n",
    "level1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d4dccf-9766-45af-99ff-61c0a5043789",
   "metadata": {},
   "source": [
    "### example using timeseries for veg/non veg at level 1 - similar to [**here**](https://bitbucket.org/geoscienceaustralia/livingearth_australia/src/master/livingearth_australia/le_plugins/FC_summary.py)\n",
    "- have taken out the water masking parts as assumes we've calculcated daily wofs (which we could do by combining the `Generating_WOfS.ipynb`)\n",
    "- output is not wrong, just has issues due to a) need at least an observation every 2 months which we don't really have, b) no water mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a141f3-2dd1-41f3-9320-6ccecb45fad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def consecutive_count_veg(tv_numpy, consecutive_numpy, required_consecutive, consec_msk_val=1):\n",
    "    '''\n",
    "    function to get consective count of veg (1) for each pixel across the time series\n",
    "\n",
    "    :param numpy.array tv_numpy: 3-D array of tv[z, y, x]\n",
    "    :param numpy.array consecutive_numpy: Bool output array for veg (1) and non veg (0)\n",
    "    :param float required_consecutive: How many consecutive 1's to be classified as veg?\n",
    "                                       FAO LCCS definition is required_consecutive = 2.\n",
    "    :param float consec_msk_val: What value to calculcate consecutives on?\n",
    "                                 Default is veg (1)      \n",
    "    '''\n",
    "\n",
    "    for y in range(tv_numpy.shape[1]):\n",
    "        for x in range(tv_numpy.shape[2]):\n",
    "            # If all the values are nan then just set output to nan and carry on\n",
    "            pixel = tv_numpy[:, y, x]\n",
    "\n",
    "            if np.all(np.isnan(pixel)):\n",
    "                consecutive_numpy[y, x] = np.nan\n",
    "                continue            \n",
    "\n",
    "            # Get counts of consecutive veg classifications\n",
    "            counts = [len(list(group)) for label, group in groupby(pixel[(~np.isnan(pixel))]) if label == 1]\n",
    "\n",
    "            if not counts:\n",
    "                consecutive_numpy[y,x] = 0\n",
    "            elif max(counts) >= required_consecutive:\n",
    "                consecutive_numpy[y,x] = 1\n",
    "            else:\n",
    "                consecutive_numpy[y,x] = 0\n",
    "\n",
    "    return consecutive_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ea744-0078-4856-98c3-b9658921ca07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    def consecutive_count_nonveg(tv_numpy, consecutive_numpy, required_consecutive, consec_msk_val=1):\n",
    "        '''\n",
    "        function to get consective count of non veg (0) for each pixel across the time series\n",
    "\n",
    "        :param numpy.array tv_numpy: 3-D array of tv[z, y, x]\n",
    "        :param numpy.array consecutive_numpy: Bool output array for veg (1) and non veg (0)\n",
    "        :param float required_consecutive: How many consecutive 0's to be classified as non veg?\n",
    "                                           FAO LCCS definition is required_consecutive = 2.\n",
    "        :param float consec_msk_val: What value to calculcate consecutives on?\n",
    "                                     Default is non veg (0) \n",
    "        '''\n",
    "\n",
    "        for y in range(tv_numpy.shape[1]):\n",
    "            for x in range(tv_numpy.shape[2]):\n",
    "                # If all the values are nan then just set output to nan and carry on\n",
    "                pixel = tv_numpy[:, y, x]\n",
    "\n",
    "                if np.all(np.isnan(pixel)):\n",
    "                    consecutive_numpy[y, x] = np.nan\n",
    "                    continue\n",
    "                    \n",
    "                # Get counts of consecutive non veg classifications (hence label == 0)\n",
    "                counts = [len(list(group)) for label, group in groupby(pixel[(~np.isnan(pixel))]) if label == 0]\n",
    "\n",
    "                # Inverse values from consecutive_count_veg to make non veg\n",
    "                if not counts:\n",
    "                    consecutive_numpy[y, x] = 1\n",
    "                elif max(counts) >= required_consecutive:\n",
    "                    consecutive_numpy[y, x] = 0\n",
    "                else:\n",
    "                    consecutive_numpy[y, x] = 1\n",
    "\n",
    "        return consecutive_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d75d0e-e291-427f-bb38-4a8723abe4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = ds_fc\n",
    "\n",
    "data_nan = masking.mask_invalid_data(data)\n",
    "\n",
    "# # Create water and low-quality fc masks\n",
    "# no_water = np.invert( (data['water'] == 128) | (data['water'] == 132) )\n",
    "high_ue = (data['UE'] > 30)\n",
    "\n",
    "# Set to null areas with high ue, but no water\n",
    "data_nan = data_nan.where(np.invert(high_ue))\n",
    "\n",
    "# Don't need this anymore\n",
    "data_nan = data_nan.drop_vars(\"UE\")\n",
    "del high_ue\n",
    "\n",
    "# # Where there's water, set pv to 0\n",
    "# data_nan['pv'] = data_nan.pv.where(no_water, 0)\n",
    "# data_nan['npv'] = data_nan.npv.where(no_water, 0)\n",
    "\n",
    "# # Where there's water, set bs to 100\n",
    "# # this artificial inflation on bs ensures water areas are classified as non-veg\n",
    "# data_nan['bs'] = data_nan.bs.where(no_water, 100)\n",
    "\n",
    "# # don't need this anymore\n",
    "# data_nan = data_nan.drop_vars(\"water\")\n",
    "# del no_water\n",
    "\n",
    "data_month = data_nan.groupby('time.month').median(dim='time')    \n",
    "\n",
    "# Create mask where pv > bs\n",
    "pv_dominant = data_month['PV'] > data_month['BS']\n",
    "pv_dominant_nan = pv_dominant.where((data_month['PV'] >= 0) & (data_month['BS'] >= 0))\n",
    "\n",
    "# Create mask where npv > bs\n",
    "npv_dominant = data_month['NPV'] > data_month['BS']\n",
    "npv_dominant_nan = npv_dominant.where((data_month['NPV'] >= 0) & (data_month['BS'] >= 0))\n",
    "\n",
    "# Veg where pv or npv are greater than bs\n",
    "tv_mask = (pv_dominant_nan + npv_dominant_nan)\n",
    "\n",
    "# make values of 2 == 1 (end result in binary veg mask)\n",
    "tv_mask_drop = np.where(tv_mask == 2, 1, tv_mask)\n",
    "tv_mask_xr = xr.DataArray(tv_mask_drop, coords=tv_mask.coords, dims=tv_mask.dims)\n",
    "\n",
    "##### veg #####\n",
    "# Executing consecutive_count function #\n",
    "# veg and non veg = 2 consecutive months\n",
    "required_consecutive = 2\n",
    "\n",
    "# Pull tv as numpy array\n",
    "tv_numpy = tv_mask_xr.values\n",
    "\n",
    "# Set up array for output (faster to pre-allocate for numba).\n",
    "# Needs to be float32 for NaN\n",
    "consecutive_numpy = np.empty((tv_numpy.shape[1], tv_numpy.shape[2]), dtype=np.float32)\n",
    "\n",
    "# For veg - run function to get array of with 1 where number of consecutive values for\n",
    "# different dates is >= required_consecutive\n",
    "consecutive_numpy_veg = consecutive_count_veg(tv_numpy, consecutive_numpy, required_consecutive)\n",
    "\n",
    "# Reduce original array to 2D\n",
    "# using max here but not important as we just want to use shape/attributes\n",
    "tv_reduce = tv_mask.max(dim='month')\n",
    "\n",
    "# Create new data array with sampe dimensions as original\n",
    "tv_summary_veg = xr.DataArray(consecutive_numpy_veg, coords=tv_reduce.coords, dims=tv_reduce.dims)\n",
    "\n",
    "##### non veg #####\n",
    "# Executing consecutive_count function #\n",
    "# veg and non veg = 2 consecutive months\n",
    "required_consecutive = 2\n",
    "\n",
    "# Pull tv as numpy array\n",
    "tv_numpy = tv_mask_xr.values\n",
    "\n",
    "# Set up array for output (faster to pre-allocate for numba).\n",
    "# Needs to be float32 for NaN\n",
    "consecutive_numpy = np.empty((tv_numpy.shape[1], tv_numpy.shape[2]), dtype=np.float32)\n",
    "\n",
    "# For non veg - run function to get array of with 0 where number of consecutive values for\n",
    "# different dates is >= required_consecutive\n",
    "consecutive_numpy_nonveg = consecutive_count_nonveg(tv_numpy, consecutive_numpy, required_consecutive)\n",
    "\n",
    "# Reduce original array to 2D\n",
    "# using max here but not important as we just want to use shape/attributes\n",
    "tv_reduce = tv_mask.max(dim='month')\n",
    "\n",
    "# Create new data array with sampe dimensions as original\n",
    "tv_summary_nonveg = xr.DataArray(consecutive_numpy_nonveg, coords=tv_reduce.coords, dims=tv_reduce.dims)\n",
    "\n",
    "# Combine veg and non veg masks (to ensure no data is correctly identified)\n",
    "tv_combine = tv_summary_veg + tv_summary_nonveg\n",
    "\n",
    "# Make values of 2 == 1 (end result in binary veg mask)\n",
    "tv_combine_drop = np.where(tv_combine == 2, 1, tv_combine)\n",
    "\n",
    "# Create new data array with sampe dimensions as original\n",
    "tv_summary = xr.DataArray(tv_combine_drop, coords=tv_combine.coords, dims=tv_combine.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1983911c-55cc-490b-95f8-9f22c3ac1a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot annual total veg (tv)\n",
    "tv_summary.plot(vmin = 0, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d74454-be41-4425-ad87-ea1af97118c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FC_Environment",
   "language": "python",
   "name": "fc_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
